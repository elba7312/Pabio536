{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `numpy` and `pandas` to hold and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Two of the most useful libraries for working with scientific data are `numpy` and `pandas`. \n",
    "\n",
    "`Numpy` is a library of math functions we need to do data analysis. \n",
    "\n",
    "`Numpy` also introduces a new object for holding groups of variables: n-dimensional arrays of data. Within `numpy` they're referred to as ndarrays, but I'll just call them arrays for this class. \n",
    "\n",
    "We'll start by introducing you to arrays and `numpy` functions, why you might want to use them, and how they work. Later we'll cover `pandas`, a \"wrapper\" for `numpy` arrays that makes them simpler to use, and `scipy`, which adds more complex mathematical and statistical functions to python using arrays. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding libraries to python\n",
    "\n",
    "First we need to import the libraries we want to use. This is the same process you used for the last homework to add a function to python, but libraries can add hundreds of new functions\n",
    "\n",
    "When we import these libraries we can give them an alias, which is easier to remember and type. The ones used below are common for these packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the description of `numpy`.\n",
    "# Remember, almost every function and library has a small help file\n",
    "\n",
    "#np?\n",
    "\n",
    "# Try hitting tab after the period to see all the `numpy` function options\n",
    "#np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `numpy` has several sub-libraries that group together functions by category, like np.random for getting random numbers, np.linalg for doing linear algebra, etc. We will mostly use np.random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy arrays: a new thing to hold other things\n",
    "\n",
    "NumPy arrays are essentially lists that have two important restrictions:\n",
    "\n",
    " - An array can only hold **one** type of data\n",
    " - Arrays are unmutable: you **can** change the contents, but you **can't** change the size of the array or the data type\n",
    "     - Why you append to an array you actually copy the array and add new data to the copy\n",
    " \n",
    "Why would we want a list with extra restrictions? The short answer is speed. The computer only needs to check the type of data once for the array, not once for each variable. This adds up when you have huge arrays like the results of an 'omics' experiment. \n",
    "\n",
    "There are a number of ways to make `numpy` arrays. You can import data from text files (covered later), you can convert a list to an array, or you can use one of the `numpy` functions that builds some basic array types useful for data analysis.\n",
    "\n",
    "Let's look at two new functions from NumPy for making arrays: `np.arange()` and `np.zeroes()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `numpy` function arange(start, stop, step) gives you an array of values\n",
    "# between the start and stop (not including the stop) incremented by step\n",
    "# The default step is 1\n",
    "a = np.arange(0,10)\n",
    "\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the size of our new array\n",
    "\n",
    "# We can do this with len(), like we did with lists\n",
    "print (len (a))\n",
    "\n",
    "# Remember how an object is a collection of variables and methods?\n",
    "# In addition to the variables contained by the array, \n",
    "# `numpy` arrays store variables _about_ the array\n",
    "\n",
    "print(a.shape) # we'll come back to this when we make arrays with more dimensions\n",
    "print(a.size)\n",
    "\n",
    "# Note that these aren't methods, so you don't use parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can get data from the array just like we did with lists and tuples with square brackets and slicing\n",
    "print(a[3])\n",
    "print(a[0:3])\n",
    "print(a[2:])\n",
    "\n",
    "# We use square brackets to assign new values to our array\n",
    "print(a)\n",
    "a[3]=99\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math operations on arrays\n",
    "Math operators ($+, -, *, /$) work on arrays by acting on each element or variable in the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (a*3)\n",
    "print (a+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use operators with two arrays\n",
    "b = np.arange(0,1,0.1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(b+a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Notice operators work with differently with arrays and lists\n",
    "# You can convert an array to a list using the method ndarray.tolist()\n",
    "# Convert a to a_list and then multiply both by three\n",
    "\n",
    "a_list = a.tolist()\n",
    "print (a)\n",
    "print(a_list)\n",
    "print(a*3)\n",
    "print (a_list*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use boolean operators on arrays\n",
    "# That gives us an array of True and False values\n",
    "print(a >= 8) # Which values are greater than or equal to 8\n",
    "print(a == 99) # Which values are equal to 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding dimensions\n",
    "\n",
    "So far all of the arrays we've worked with have been one dimensional. NumPy arrays can be any number of dimensions. What does that mean? It just means we are keeping track of that many different variables for each sample. \n",
    "\n",
    "M. tuberculosis has ~4,000 genes. If we do an RNAseq experiment with three samples and measure the expression of each gene for each sample, we are generating 4,000 dimensional data. We could plot the expression of one gene on a line, two genes on a grid, three genes in 3D, maybe show data for another few genes by mapping that to the size and color of the marker. \n",
    "\n",
    "Let's start by making a two dimensional NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's reshape our 1D array from above using the ndarray.reshape() method\n",
    "# We know from a couple cells above that a is 10 variables long\n",
    "# Reshape that to a 2 by 5 table\n",
    "print(a.reshape(2,5))\n",
    "\n",
    "# Note that didn't change the shape of a!\n",
    "print('a is still:',a)\n",
    "\n",
    "# If you don't store the reshaped array it simply shows us the table... sometimes thats all we want\n",
    "# Otherwise you can store that view in another variable, or overwrite the existing variable\n",
    "a = a.reshape(2,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an array with three dimensions, each of length three\n",
    "a_3d = np.arange(1,28,1).reshape(3,3, 3)\n",
    "print(a_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use mathematical operators just like we did with the 1D arrays\n",
    "print(a_3d*3)\n",
    "print(a_3d**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before you can you can get specific values or ranges of values using square brackets and slices\n",
    "print(\"a is:\\n\",a)\n",
    "print(\"a_3d is:\\n\",a_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the fourth value in the first column from a\n",
    "a[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the second row of values from a\n",
    "# Remember, if you want all of the values use a colon\n",
    "a[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first layer of a_3d\n",
    "a_3d[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think of two ways to get the last layer of a_3d\n",
    "a_3d[:,:,2] == a_3d[:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for modifying arrays\n",
    "We've already seen ndarray.reshape for changing the structure of our data. We can also divide arrays with np.split() and add data with np.append() or np.stack()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The np.split() function will split an array into equal sized chunks\n",
    "# You can specify if you want to break up the array by rows, columns, sheets, etc.\n",
    "np.split(a_3d, 3, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that NumPy arrays are immutable, so any change we make is just a \"view\" until we make a copy\n",
    "# For instance, we can add data to an array using np.append, but that won't change the original array\n",
    "np.append(a, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use an array in a for loop it iterates over the rows\n",
    "for row in a:\n",
    "    print(row)\n",
    "    print(row+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FInally, we can transpose an array using array.T()\n",
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy functions to make arrays shine\n",
    "\n",
    "NumPy gives you a library of functions that work with arrays. These can be split into functions that:\n",
    " - modify the structure of arrays\n",
    " - access data in arrays\n",
    " - use arrays as inputs to a range of mathematical functions \n",
    "\n",
    "I'll cover a few of the most useful functons here, but we will see many more as the class goes on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magic functions\n",
    "The first function isn't actually part of NumPy. \n",
    "\n",
    "Python has a set of \"magic\" commands that work on memory and the operating system. Not surprisingly, you can easily cause things to crash doing that, so magic commands limit your ability to do damage by only giving you a few powerful functions. All magic functions start with a \"%\" symbol. \n",
    "\n",
    "We will run into a few more of these later, but for now I just want to show you one really useful magic function: `%whos`.\n",
    "\n",
    "You may find that you lose track of the variables you've created so far. Let's see whats there with `%whos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show us every variable in memory\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show us every variable in memory that has the data type 'ndarray'\n",
    "%whos ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random number generators\n",
    "\n",
    "Random numbers are a good way of simulating expected results or sampling a random subset of data. \n",
    "\n",
    "We can generate random numbers using the functions in the np.random sub-library. These numbers can be taken from a uniform distribution (all numbers equally possible) or from a normal distribution (a 'bell-shape' centered on the mean) or many other distributions we won't cover here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start by setting a random seed so that all our random variables match\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random integer with randint(start, stop(not included), number of values desired)\n",
    "np.random.randint(1, 11, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random integers between 0 and 10 in a 2 by 2 array\n",
    "print(np.random.randint(0, 10, size=[2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three random floating-point number between 0 and 1\n",
    "print(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution with mean=0 and variance=1 in a 1 by 5 array\n",
    "print(np.random.randn(1, 5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 10 items from a given list, with equal probability\n",
    "print(np.random.choice(['a', 'e', 'i', 'o', 'u'], size=10))  \n",
    "\n",
    "# Pick 10 items from a given list with a predefined probability 'p'\n",
    "print(np.random.choice(['a', 'e', 'i', 'o', 'u'], size=10, p=[0.3, .1, 0.1, 0.4, 0.1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a 5 by 5 matrix of random numbers from the normal distribution\n",
    "# And let's be a bit fancy- keep the mean at zero but\n",
    "# use a for loop and fill in the first row with sd =1, the second with sd = 2, etc.\n",
    "\n",
    "normarray = np.zeros ((5,5))\n",
    "\n",
    "for row in np.arange(5):\n",
    "    randrow = np.random.randn(5)*(row + 1)\n",
    "    normarray[row, :] = randrow\n",
    "\n",
    "normarray = normarray.round(3)\n",
    "print(normarray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built in methods for NumPy arrays \n",
    "Lastly lets look at some of the methods that every NumPy array has. We've already used ndarray.tolist() and nda.reshape().\n",
    "\n",
    "Now we will learn how to get the average, min, max, or median of ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nda.mean() gives you the mean of the whole array\n",
    "print(normarray.mean())\n",
    "\n",
    "# You can specify if you want to average the rows (axis=0) or columns (axis=1)\n",
    "print(normarray.mean(axis=0))\n",
    "print(normarray.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You get min, max, or median the same way\n",
    "print(normarray.max(axis=1))\n",
    "print(normarray.min(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pandas` for tidy data management\n",
    "\n",
    "For many of us, Excel is the go-to program for data analysis. `R` (another programming language) has been popular for analysis and modeling, partly because `R` has a type of object called a DataFrame that functions like an Excel spreadsheet in computer memory. \n",
    "\n",
    "`Pandas` brings DataFrames to python, introducing a convenient way to import, store, and save tables of data. `Pandas` is a \"wrapper\" around NumPy - `pandas` methods use NumPy functions and objects, but tries to make things simpler. The trade off is that `pandas` is slower, but for the types of analysis biologists do that will rarely be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data into a DataFrame\n",
    "Let's import some data to work with. `Pandas` provides simple tools for importing from Excel, csv, or any other common data format. Here we are going to use the `read_csv` command to pull in a table of RNAseq data from a [melanoma study from 2017](https://www.nature.com/articles/s41467-017-02353-y) published in Nature Communications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` arrays let you slice and manipulate data and perform lots of mathematical operations on those arrays. `Pandas` builds on that functionality by focusing on rigidly defined lists (Series) and 2D tables (DataFrames aka \"panel data\", whence comes `pandas`). `Pandas` also makes data import and manipulation simpler and more intuitive than `numpy`. However in exchange for being simpler to write and read, `pandas` can be slower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have data already you can import it directly from a text file like a comma seperated values, or csv, file. `Pandas` makes this easy. But in `numpy`, well...\n",
    "\n",
    "**DO NOT TRY TO UNDERSTAND THIS CODE** \n",
    "This is the code for importing csv files with `numpy`:\n",
    "```python\n",
    "import csv\n",
    "\n",
    "with open('employee_birthday.txt', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} works in the {row[\"department\"]} department, and was born in {row[\"birthday month\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "```\n",
    "OK, that's probably unfair to NumPy. There are easier ways to do this now, but in a lot of older code this is exactly what data import looks like. \n",
    "\n",
    "This is much easier to do in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing a table of gene expression data using the `pandas` function `pd.read_csv()` and a table of metadata using `pd.read_excel()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas` DataFrames and Series\n",
    "`Pandas` introduces two new ways of collecting variables:\n",
    "\n",
    " - Series: A named list of values, all of the same type\n",
    " - DataFrame: A Excel spreadsheet in computer memory made by bundling Series Each column is a different Series of data, and each row is a separate observation or sample.\n",
    "\n",
    "A `pandas` Series is a one dimensional NumPy array with extra methods attached.\n",
    "A DataFrame (df) is a collection of related Series, where each column of data is a Series and each row is a different observation of those variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import comma-seperated data from a text file\n",
    "\n",
    "df = pd.read_csv('data\\GSE88741-expression.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the imported data\n",
    "# The number of rows and columns in a DataFrame can be found at df.shape\n",
    "print (\"Dimensions of DataFrame:\",df.shape,\"\\n\")\n",
    "\n",
    "# Let's take a look at the top 5 rows of `df` using df.head()\n",
    "print (df.head())\n",
    "\n",
    "# Note: Why don't we need parentheses after `df.shape`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# describe() shows a quick statistics summary of your data\n",
    "# round() limits the number of significant digits\n",
    "# You can chain together functions like we do here with round\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a large dataset, so lets take a small random sample to work with\n",
    "# the sample() method randomly selects a number of rows or columns from a larger DataFrame\n",
    "# We are setting the random_state here so that we all use the same random genes\n",
    "df_sample = df.sample(100, axis = 0, random_state = 333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Dimensions of DataFrame:\",df_sample.shape)\n",
    "print()\n",
    "print (df_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that was realtively painless, but it required you to save your data as a csv file. Much of the data I work with is in Excel spreadsheets, and you _can_ save those as csv files. However `pandas` lets you import directly from Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring in the metadata from an excel spreadsheet\n",
    "meta = pd.read_excel(\"data/GSE88741-metadata.xlsx\", index_col=1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's extract the Sample Titles and use them to replace the ugly GSM names\n",
    "columns = meta.index\n",
    "print (type(columns))\n",
    "df_sample.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how we set the column names above\n",
    "# We can use that command to show us index and column names as well\n",
    "print(df_sample.index)\n",
    "print()\n",
    "print(df_sample.columns)\n",
    "print()\n",
    "print(df_sample.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and sorting\n",
    "Getting subsets of data out of `pandas` DataFrames is done primarily in one of two ways.\n",
    "\n",
    "If you want to search for row and column names, you use .loc(). For instance, if I want the value from the 3rd row and 2nd column you would use `df.loc(\n",
    "You can instead use the index numbers to select the data you want using .iloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort by the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.UACC_62_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can send our DataFrame into a `numpy` array\n",
    "# ndarrays can only be one type of data, so if we added any metadata\n",
    "# this would convert to whatever data type works for all data types present\n",
    "\n",
    "nda = df.to_numpy()\n",
    "type(nda)\n",
    "#nda.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework for Class 5\n",
    "\n",
    "Let's use NumPy arrays and functions with pandas data frames in a demo experiment. \n",
    "\n",
    "We have a new drug, excitin (tm), that we think acts by blocking fatty acid synthesis. If we are right, genes in that pathway are likely induced to try and compensate. We are going to check if we are right by looking at expression of those genes in the presence and absence of excitin. \n",
    "\n",
    "We don't have a good idea *when* we expect to see the FA synthesis pathway induced, so we are sampling every 8 hours for three days in the presence and absence of excitin. We will measure the expression of six genes at each time point, three FA biosynthesis genes and three control genes that we don't expect to see changed. \n",
    "\n",
    "While the experiment is running lets use dummy data to set up an analysis pipeline.\n",
    "\n",
    "For the homework you need to:\n",
    "> 1. Make an array containing all of the time points in this experiment\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up an array of sampling times using a new function: np.arange()\n",
    "# Pass np.arange() the start, stop (not included), and step size\n",
    "\n",
    "sample_times = np.arange(0, 3*24+1, 8)\n",
    "\n",
    "print(sample_times)\n",
    "print(type(sample_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make an array to hold all of our results when we get them\n",
    "# Let's say we're going to use qRT-PCR to measure expression of five genes at each time point\n",
    "# We can use np.zeroes((tuple)) to set up an array filled with zeroes,\n",
    "# where tuple is the size of the array we want, 10 by 5\n",
    "\n",
    "array_size = (10, 5)\n",
    "data_table = np.zeros (array_size)\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a table of data that assumes the null hypothesis, i.e. we won't see any expression changes. If that's the case we will have a mean of zero (no change) with some noise that follows a normal distribution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
